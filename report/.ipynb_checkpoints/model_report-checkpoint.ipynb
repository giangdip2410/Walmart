{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLineModelレポート\n",
    "## 目次\n",
    "1. Import\n",
    "2. なぜLightGBMか？\n",
    "3. 工夫した点\n",
    "4. 考察\n",
    "5. 課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## なぜLightGBMか？\n",
    "- 欠損値をそのまま扱える\n",
    "- 計算速度が速い\n",
    "- feature importanceが見れる\n",
    "- 精度が出やすい\n",
    "- CVを切るのが楽(時系列として扱わなくてもいいので)\n",
    "- 時系列は大事だが、週番号カテゴリと見ても予測できるだろうと考えた\n",
    "- パラメータチューニングが楽\n",
    "- 実装が楽\n",
    "\n",
    "今回は、分析、考察をするというのが課題であったため、実験を多く回せ、解釈性の高いLightGBMを初手として選んだ。\n",
    "BaseLineモデルとしては比較的精度が出せたため(銅圏))、このモデルをベースにNNなどを考察しながら組んでいきたい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工夫した点\n",
    "- 特徴量  \n",
    "    LSTMや、Transformerと比べ、LightGBMは過去の情報を加味して予測するのが得意でない。  \n",
    "    そのため、一年前のweekly_Salesや移動平均、変化率、週や月ごとのWeekly_Salesを特徴として入れることで過去の情報を利用して予測してくれるようにした。  \n",
    "    他にも、LightGBMは様々な要因を考慮できることから、カテゴリで集約した特徴量を多く入れた。\n",
    "- CV  \n",
    "LightGBMを用いて、週番号をカテゴリとして扱ったため時系列を考慮するような切り方を考える必要がなくなった。(未来も過去もある程度マスクできるので)  \n",
    "結果として、LB,CVの相関は取れており初手としては良い戦略だったと考える。  \n",
    "時系列モデルを作るときは要注意\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv-vs-lb\n",
    "cv_private = pd.DataFrame([[11786,9505,9537,9454,9496,5910,5114],[7059,6569,6863,6473,6437,3544,2921]],index=['cv','private']).T\n",
    "sns.regplot(data=cv_private,x='cv',y='private')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考察\n",
    "- feature importanceを見た感じ、Before_Salesはかなり効いている。testでも一年前との相関はかなり高いようである。実際lbも3000程度改善した。\n",
    "- 反面、大量に作った集約特徴量はあまり効いていない。適宜減らしていくべき。\n",
    "- DeptやStoreのimportanceも高いため、Dept,Store毎にモデルを作っても良さそう。\n",
    "- クリスマス付近はかなりよく予測できているような気がする。\n",
    "- 時系列を考慮しないようなモデルを作ったが、モデル自体が過去の情報を使ってくれたほうが良さそう。\n",
    "- 全体的に低く予測してしまっているので、高く予測するようなモデルを作ってアンサンブルしても良さそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "im = Image.open(\"../output/sub_007/img.jpg\")\n",
    "im_list = np.asarray(im)\n",
    "plt.imshow(im_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "- before Sales等を特徴量としているので、cvが信用できない。 → やはり時系列を考慮したモデル(Transformer、LSTM,ARMA等)を作るべき\n",
    "- 無理やりLightGBMに時系列を学習させているので、情報を自然に学習させれていない →　時系列モデルを作る\n",
    "- 時系列モデルを作るなら、どこ学習データとしてどこを検証データとするかが難しい。(単純なTimeSriesKfoldじゃダメそう)\n",
    "- WMAEというmetricに対して学習を最適化出来ていない。IsHolidayのときはWeekly_Salesを5倍だったり二乗だったりしてlossを大きくしたほうが良さそう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
